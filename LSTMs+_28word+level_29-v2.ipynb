{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_document(name):\n",
    "    file = open(name, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿The Project Gutenberg EBook of The Jungle Book, by Rudyard Kipling\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "with this eBook or online at www.gutenberg.org\n",
      "\n",
      "\n",
      "Title: The Jungle Book\n",
      "\n",
      "Author: Rudyard Kipling\n",
      "\n",
      "Release Date: January 16, 2006 [EBook #236]\n",
      "Last Updated: October 6, 2016\n",
      "\n",
      "Language: English\n",
      "\n",
      "Character set encoding: UTF-8\n",
      "\n",
      "*** START OF THIS PROJECT GUTENBERG EBOOK THE JUNGLE BOOK ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Produced by An Anonymous Volunteer and David Widger\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE JUNGLE BOOK\n",
      "\n",
      "By Rudyard Kipling\n",
      "\n",
      "\n",
      "\n",
      "Contents\n",
      "\n",
      "     Mowgli’s Brothers\n",
      "     Hunting-Song of the Seeonee Pack\n",
      "     Kaa’s Hunting\n",
      "     Road-Song of the Bandar-Log\n",
      "     “Tiger! Tiger!”\n",
      "      Mowgli’s Song\n",
      "     The White Seal\n",
      "     Lukannon\n",
      "     “Rikki-Tikki-Tavi”\n",
      "      Darzee’s Chant\n",
      "     Toomai of the Elephants\n",
      "     Shiv and the Grasshopper\n",
      "     Her Majesty’s Servants\n",
      "     Parade Song of the Camp Animals\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Mowgli’s Brothers\n",
      "\n",
      "     Now Rann the Kite brings home the night\n",
      "        That Mang the Bat sets free--\n",
      "     The herds are shut in byre and hut\n",
      "        For loosed till dawn are we.\n",
      "     This is the hour of pride and power,\n",
      "        Talon and tush and claw.\n",
      "     Oh, hear the call!--Good hunting all\n",
      "        That keep the Jungle Law!\n",
      "     Night-Song in the Jungle\n",
      "\n",
      "It was seven o’clock of a very warm evening in the Seeonee hills when\n",
      "Father Wolf woke up from his day’s rest, scratched himself, yawned, and\n",
      "spread out his paws one after the other to get rid of the sleepy feeling\n",
      "in their tips. Mother Wolf lay with her big gray nose dropped across her\n",
      "four tumbling, squealing cubs, and the moon shone into the mouth of the\n",
      "cave where they all lived. “Augrh!” said Father Wolf. “It is time to\n",
      "hunt again.” He was going to spring down hill when a little shadow with\n",
      "a bushy tail crossed the threshold and whined: “Good luck go with you, O\n",
      "Chief of the Wolves. And good luck and\n"
     ]
    }
   ],
   "source": [
    "# load document\n",
    "input_filename = './Data/junglebook.txt'\n",
    "doc = load_document(input_filename)\n",
    "print(doc[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "293051\n"
     ]
    }
   ],
   "source": [
    "print(type(doc))\n",
    "print(len(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import String module\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Find tokens from input document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "doc2 = doc.replace('--', ' ') ## replace '--' to ''\n",
    "tokens = doc2.split()  ## convert the document into tokens\n",
    "table = str.maketrans('', '', string.punctuation) ## \n",
    "tokens2 = [w.translate(table) for w in tokens]\n",
    "tokens3 = [word for word in tokens2 if word.isalpha()]\n",
    "tokens4 = [word.lower() for word in tokens3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿The Project Gutenberg EBook of The Jungle Book, by Rudyard Kipling\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "with this eBook or online at www.gutenberg.org\n",
      "\n",
      "\n",
      "Title: The Jungle Book\n",
      "\n",
      "Author: Rudyard Kipling\n",
      "\n",
      "Release Date: January 16, 2006 [EBook #236]\n",
      "Last Updated: October 6, 2016\n",
      "\n",
      "Language: English\n",
      "\n",
      "Character set encoding: UTF-8\n",
      "\n",
      "*** ST\n"
     ]
    }
   ],
   "source": [
    "print(doc2[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffThe', 'Project', 'Gutenberg', 'EBook', 'of', 'The', 'Jungle', 'Book,', 'by', 'Rudyard', 'Kipling', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever.', 'You', 'may', 'copy', 'it,', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www.gutenberg.org', 'Title:', 'The', 'Jungle', 'Book', 'Author:', 'Rudyard', 'Kipling', 'Release', 'Date:', 'January', '16,', '2006', '[EBook', '#236]', 'Last', 'Updated:', 'October', '6,', '2016', 'Language:', 'English', 'Character', 'set', 'encoding:', 'UTF-8', '***', 'START', 'OF', 'THIS', 'PROJECT', 'GUTENBERG', 'EBOOK', 'THE', 'JUNGLE', 'BOOK', '***', 'Produced', 'by', 'An', 'Anonymous', 'Volunteer', 'and', 'David', 'Widger', 'THE']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffThe', 'Project', 'Gutenberg', 'EBook', 'of', 'The', 'Jungle', 'Book', 'by', 'Rudyard', 'Kipling', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'You', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 'reuse', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'wwwgutenbergorg', 'Title', 'The', 'Jungle', 'Book', 'Author', 'Rudyard', 'Kipling', 'Release', 'Date', 'January', '16', '2006', 'EBook', '236', 'Last', 'Updated', 'October', '6', '2016', 'Language', 'English', 'Character', 'set', 'encoding', 'UTF8', '', 'START', 'OF', 'THIS', 'PROJECT', 'GUTENBERG', 'EBOOK', 'THE', 'JUNGLE', 'BOOK', '', 'Produced', 'by', 'An', 'Anonymous', 'Volunteer', 'and', 'David', 'Widger', 'THE']\n"
     ]
    }
   ],
   "source": [
    "print(tokens2[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Project', 'Gutenberg', 'EBook', 'of', 'The', 'Jungle', 'Book', 'by', 'Rudyard', 'Kipling', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'You', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 'reuse', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'wwwgutenbergorg', 'Title', 'The', 'Jungle', 'Book', 'Author', 'Rudyard', 'Kipling', 'Release', 'Date', 'January', 'EBook', 'Last', 'Updated', 'October', 'Language', 'English', 'Character', 'set', 'encoding', 'START', 'OF', 'THIS', 'PROJECT', 'GUTENBERG', 'EBOOK', 'THE', 'JUNGLE', 'BOOK', 'Produced', 'by', 'An', 'Anonymous', 'Volunteer', 'and', 'David', 'Widger', 'THE', 'JUNGLE', 'BOOK', 'By', 'Rudyard', 'Kipling', 'Contents', 'Brothers', 'HuntingSong', 'of']\n"
     ]
    }
   ],
   "source": [
    "print(tokens3[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['project', 'gutenberg', 'ebook', 'of', 'the', 'jungle', 'book', 'by', 'rudyard', 'kipling', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'you', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 'reuse', 'it', 'under', 'the', 'terms', 'of', 'the', 'project', 'gutenberg', 'license', 'included', 'with', 'this', 'ebook', 'or', 'online', 'at', 'wwwgutenbergorg', 'title', 'the', 'jungle', 'book', 'author', 'rudyard', 'kipling', 'release', 'date', 'january', 'ebook', 'last', 'updated', 'october', 'language', 'english', 'character', 'set', 'encoding', 'start', 'of', 'this', 'project', 'gutenberg', 'ebook', 'the', 'jungle', 'book', 'produced', 'by', 'an', 'anonymous', 'volunteer', 'and', 'david', 'widger', 'the', 'jungle', 'book', 'by', 'rudyard', 'kipling', 'contents', 'brothers', 'huntingsong', 'of']\n"
     ]
    }
   ],
   "source": [
    "print(tokens4[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{33: None,\n",
       " 34: None,\n",
       " 35: None,\n",
       " 36: None,\n",
       " 37: None,\n",
       " 38: None,\n",
       " 39: None,\n",
       " 40: None,\n",
       " 41: None,\n",
       " 42: None,\n",
       " 43: None,\n",
       " 44: None,\n",
       " 45: None,\n",
       " 46: None,\n",
       " 47: None,\n",
       " 58: None,\n",
       " 59: None,\n",
       " 60: None,\n",
       " 61: None,\n",
       " 62: None,\n",
       " 63: None,\n",
       " 64: None,\n",
       " 91: None,\n",
       " 92: None,\n",
       " 93: None,\n",
       " 94: None,\n",
       " 95: None,\n",
       " 96: None,\n",
       " 123: None,\n",
       " 124: None,\n",
       " 125: None,\n",
       " 126: None}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 51473\n",
      "Unique Tokens: 5027\n"
     ]
    }
   ],
   "source": [
    "# clean document\n",
    "print('Total Tokens: %d' % len(tokens4))\n",
    "print('Unique Tokens: %d' % len(set(tokens4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize the document into sequences.  Each sequence (row) contains 51 words.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 51422\n"
     ]
    }
   ],
   "source": [
    "# organize into sequences (of length 50) of tokens\n",
    "length = 50 + 1\n",
    "sequences = list()\n",
    "for i in range(length, len(tokens4)):\n",
    "    # select sequence of tokens\n",
    "    seq = tokens4[i-length:i] ## token 1 to 51, 2 to 52,,,,\n",
    "    # convert into a line\n",
    "    line = ' '.join(seq)\n",
    "    sequences.append(line)\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['at', 'our', 'web', 'site', 'which', 'has', 'the', 'main', 'pg', 'search', 'facility', 'httpwwwgutenbergorg', 'this', 'web', 'site', 'includes', 'information', 'about', 'project', 'gutenbergtm', 'including', 'how', 'to', 'make', 'donations', 'to', 'the', 'project', 'gutenberg', 'literary', 'archive', 'foundation', 'how', 'to', 'help', 'produce', 'our', 'new', 'ebooks', 'and', 'how', 'to', 'subscribe', 'to', 'our', 'email', 'newsletter', 'to', 'hear', 'about', 'new']\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "print(seq)\n",
    "print(len(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at our web site which has the main pg search facility httpwwwgutenbergorg this web site includes information about project gutenbergtm including how to make donations to the project gutenberg literary archive foundation how to help produce our new ebooks and how to subscribe to our email newsletter to hear about new\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(line)\n",
    "print(type(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project gutenberg ebook of the jungle book by rudyard kipling this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or',\n",
       " 'gutenberg ebook of the jungle book by rudyard kipling this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online',\n",
       " 'ebook of the jungle book by rudyard kipling this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at',\n",
       " 'of the jungle book by rudyard kipling this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg',\n",
       " 'the jungle book by rudyard kipling this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg title',\n",
       " 'jungle book by rudyard kipling this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg title the',\n",
       " 'book by rudyard kipling this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg title the jungle',\n",
       " 'by rudyard kipling this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg title the jungle book',\n",
       " 'rudyard kipling this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg title the jungle book author',\n",
       " 'kipling this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at wwwgutenbergorg title the jungle book author rudyard']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Sequence data into the local drive (/data/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tokens to file, one dialog per line\n",
    "output_filename = './Data/junglebook_sequences.txt'\n",
    "    \n",
    "data = '\\n'.join(sequences)\n",
    "file = open(output_filename, 'w')\n",
    "file.write(data)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Sequence files from the local drive (/data/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load document into memory\n",
    "\n",
    "input_filename = './Data/junglebook_sequences.txt'\n",
    "\n",
    "file = open(input_filename, 'r')\n",
    "text = file.read()\n",
    "file.close()\n",
    "\n",
    "lines = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "project gutenberg ebook of the jungle book by rudyard kipling this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or\n",
      "gutenberg ebook of the jungle book by rudyard kipling this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online\n",
      "ebook of the jungle book by rudyard kipling this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online at\n",
      "of the jungle book by rudyard kipling this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reu\n",
      "\n",
      "Length of input file :  13420601\n",
      "\n",
      "Thpe of lines :  <class 'list'>\n",
      "\n",
      "Length of lines :  51422\n",
      "First row of lines :  gutenberg ebook of the jungle book by rudyard kipling this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or reuse it under the terms of the project gutenberg license included with this ebook or online\n"
     ]
    }
   ],
   "source": [
    "print(type(text))\n",
    "print(text[:1000])\n",
    "print(\"\\nLength of input file : \" , len(text))\n",
    "\n",
    "print(\"\\nThpe of lines : \", type(lines))\n",
    "print(\"\\nLength of lines : \" , len(lines))\n",
    "print(\"First row of lines : \", lines[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing the string lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras_preprocessing.text.Tokenizer object at 0x7f55f8454f60>\n",
      "<keras_preprocessing.text.Tokenizer object at 0x7f55f8454f60>\n"
     ]
    }
   ],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "print(tokenizer)\n",
    "tokenizer.fit_on_texts(lines)\n",
    "print(tokenizer)\n",
    "sequences = tokenizer.texts_to_sequences(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "51422\n",
      "[297, 660, 3, 1, 60, 1046, 36, 1466, 1465, 47, 660, 13, 12, 1, 254, 3, 512, 901, 24, 51, 1464, 2, 15, 285, 51, 2664, 2663, 23, 127, 538, 20, 200, 20, 86, 28, 2662, 20, 131, 1, 330, 3, 1, 97, 297, 443, 1869, 15, 47, 660, 28, 1212]\n"
     ]
    }
   ],
   "source": [
    "print(type(sequences))\n",
    "print(len(sequences))\n",
    "print(sequences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras_preprocessing.text.Tokenizer object at 0x7f55f8454f60>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5028\n"
     ]
    }
   ],
   "source": [
    "# vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1 \n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(51422, 51)\n",
      "[ 297  660    3    1   60 1046   36 1466 1465   47  660   13   12    1\n",
      "  254    3  512  901   24   51 1464    2   15  285   51 2664 2663   23\n",
      "  127  538   20  200   20   86   28 2662   20  131    1  330    3    1\n",
      "   97  297  443 1869   15   47  660   28 1212]\n"
     ]
    }
   ],
   "source": [
    "# separate into input and output\n",
    "sequences2 = array(sequences)\n",
    "print(type(sequences2))\n",
    "print(sequences2.shape)\n",
    "print(sequences2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51422, 50)\n",
      "[ 297  660    3    1   60 1046   36 1466 1465   47  660   13   12    1\n",
      "  254    3  512  901   24   51 1464    2   15  285   51 2664 2663   23\n",
      "  127  538   20  200   20   86   28 2662   20  131    1  330    3    1\n",
      "   97  297  443 1869   15   47  660   28]\n",
      "(51422,)\n",
      "[  28 1212   24 1468 2665    1   60 1046 2666 1466 1465 2667 1469 2668\n",
      "  660  141 1871 1872  902 1470 2669  273 2670 1047    3   47   97  297\n",
      "  660    1   60 1046 1471   36  102 1873 1472    2 1874 1875    1   60\n",
      " 1046   36 1466 1465 2671  539 1876    3    1  722  118  232 1877    3\n",
      "    1  274  299    1  160  194  474 1878   91    3    1  100  723    2\n",
      "    1 1473  128 1879  903  299    3    1  263  802  539  104  724    1\n",
      "  725 2672  726    1  112    9 1048    1  904 1474  307    1 1049   35\n",
      "  445    7]\n"
     ]
    }
   ],
   "source": [
    "Input, Output = sequences2[:,:-1], sequences2[:,-1]\n",
    "print(Input.shape)\n",
    "print(Input[1])\n",
    "print(Output.shape)\n",
    "print(Output[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-fc3b48847a67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mcategorical\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Output2 = to_categorical(Output, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-a97d4d409229>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msequences2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequences2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mcategorical\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# separate into input and output\n",
    "sequences2 = array(sequences)\n",
    "Input, Output = sequences2[:,:-1], sequences2[:,-1]\n",
    "Output = to_categorical(Output, num_classes=vocab_size)\n",
    "sequence_length = Input.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 100)           502800    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50, 200)           240800    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5028)              1010628   \n",
      "=================================================================\n",
      "Total params: 2,115,228\n",
      "Trainable params: 2,115,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "from keras.layers import Dropout\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=sequence_length))\n",
    "model.add(LSTM(200, return_sequences=True))\n",
    "model.add(LSTM(200))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "51422/51422 [==============================] - 517s 10ms/step - loss: 6.6069 - acc: 0.0682\n",
      "Epoch 2/75\n",
      "51422/51422 [==============================] - 501s 10ms/step - loss: 6.2250 - acc: 0.0721\n",
      "Epoch 3/75\n",
      "51422/51422 [==============================] - 494s 10ms/step - loss: 6.0805 - acc: 0.0827\n",
      "Epoch 4/75\n",
      "51422/51422 [==============================] - 453s 9ms/step - loss: 5.9354 - acc: 0.0911\n",
      "Epoch 5/75\n",
      "51422/51422 [==============================] - 451s 9ms/step - loss: 5.8014 - acc: 0.1025\n",
      "Epoch 6/75\n",
      "51422/51422 [==============================] - 448s 9ms/step - loss: 5.6800 - acc: 0.1126\n",
      "Epoch 7/75\n",
      "51422/51422 [==============================] - 448s 9ms/step - loss: 5.5646 - acc: 0.1198\n",
      "Epoch 8/75\n",
      "51422/51422 [==============================] - 447s 9ms/step - loss: 5.4614 - acc: 0.1267\n",
      "Epoch 9/75\n",
      "51422/51422 [==============================] - 447s 9ms/step - loss: 5.3677 - acc: 0.1315\n",
      "Epoch 10/75\n",
      "51422/51422 [==============================] - 449s 9ms/step - loss: 5.2885 - acc: 0.1342\n",
      "Epoch 11/75\n",
      "51422/51422 [==============================] - 450s 9ms/step - loss: 5.2218 - acc: 0.1380\n",
      "Epoch 12/75\n",
      "51422/51422 [==============================] - 449s 9ms/step - loss: 5.1429 - acc: 0.1402\n",
      "Epoch 13/75\n",
      "51422/51422 [==============================] - 449s 9ms/step - loss: 5.0917 - acc: 0.1424\n",
      "Epoch 14/75\n",
      "51422/51422 [==============================] - 448s 9ms/step - loss: 5.0171 - acc: 0.1452\n",
      "Epoch 15/75\n",
      "51422/51422 [==============================] - 448s 9ms/step - loss: 4.9520 - acc: 0.1473\n",
      "Epoch 16/75\n",
      "51422/51422 [==============================] - 448s 9ms/step - loss: 4.8880 - acc: 0.1506\n",
      "Epoch 17/75\n",
      "51422/51422 [==============================] - 447s 9ms/step - loss: 4.8307 - acc: 0.1551\n",
      "Epoch 18/75\n",
      "51422/51422 [==============================] - 448s 9ms/step - loss: 4.8129 - acc: 0.1550\n",
      "Epoch 19/75\n",
      "51422/51422 [==============================] - 450s 9ms/step - loss: 4.7857 - acc: 0.1548\n",
      "Epoch 20/75\n",
      "51422/51422 [==============================] - 449s 9ms/step - loss: 4.7032 - acc: 0.1593\n",
      "Epoch 21/75\n",
      "51422/51422 [==============================] - 450s 9ms/step - loss: 4.6548 - acc: 0.1600\n",
      "Epoch 22/75\n",
      "51422/51422 [==============================] - 448s 9ms/step - loss: 4.5812 - acc: 0.1629\n",
      "Epoch 23/75\n",
      "51422/51422 [==============================] - 447s 9ms/step - loss: 4.5474 - acc: 0.1641\n",
      "Epoch 24/75\n",
      "51422/51422 [==============================] - 448s 9ms/step - loss: 4.4725 - acc: 0.1664\n",
      "Epoch 25/75\n",
      "51422/51422 [==============================] - 447s 9ms/step - loss: 4.5027 - acc: 0.1659\n",
      "Epoch 26/75\n",
      "51422/51422 [==============================] - 449s 9ms/step - loss: 4.4486 - acc: 0.1674\n",
      "Epoch 27/75\n",
      "51422/51422 [==============================] - 448s 9ms/step - loss: 4.3099 - acc: 0.1745\n",
      "Epoch 28/75\n",
      "51422/51422 [==============================] - 452s 9ms/step - loss: 4.2418 - acc: 0.1782\n",
      "Epoch 29/75\n",
      "51422/51422 [==============================] - 462s 9ms/step - loss: 4.2303 - acc: 0.1788\n",
      "Epoch 30/75\n",
      "51422/51422 [==============================] - 448s 9ms/step - loss: 4.1416 - acc: 0.1838\n",
      "Epoch 31/75\n",
      "51422/51422 [==============================] - 450s 9ms/step - loss: 4.0701 - acc: 0.1886\n",
      "Epoch 32/75\n",
      "51422/51422 [==============================] - 448s 9ms/step - loss: 4.0057 - acc: 0.1921\n",
      "Epoch 33/75\n",
      "51422/51422 [==============================] - 448s 9ms/step - loss: 3.9404 - acc: 0.1977\n",
      "Epoch 34/75\n",
      "51422/51422 [==============================] - 448s 9ms/step - loss: 3.8961 - acc: 0.2004\n",
      "Epoch 35/75\n",
      "51422/51422 [==============================] - 450s 9ms/step - loss: 3.8313 - acc: 0.2064\n",
      "Epoch 36/75\n",
      "51422/51422 [==============================] - 449s 9ms/step - loss: 3.7746 - acc: 0.2139\n",
      "Epoch 37/75\n",
      "51422/51422 [==============================] - 450s 9ms/step - loss: 3.7493 - acc: 0.2157\n",
      "Epoch 38/75\n",
      "51422/51422 [==============================] - 449s 9ms/step - loss: 3.6876 - acc: 0.2225\n",
      "Epoch 39/75\n",
      "51422/51422 [==============================] - 447s 9ms/step - loss: 3.6356 - acc: 0.2274\n",
      "Epoch 40/75\n",
      "51422/51422 [==============================] - 451s 9ms/step - loss: 3.5717 - acc: 0.2344\n",
      "Epoch 41/75\n",
      "51422/51422 [==============================] - 447s 9ms/step - loss: 3.5353 - acc: 0.2374\n",
      "Epoch 42/75\n",
      "51422/51422 [==============================] - 448s 9ms/step - loss: 3.4846 - acc: 0.2462\n",
      "Epoch 43/75\n",
      "51422/51422 [==============================] - 448s 9ms/step - loss: 3.4388 - acc: 0.2502\n",
      "Epoch 44/75\n",
      "51422/51422 [==============================] - 455s 9ms/step - loss: 3.3920 - acc: 0.2545\n",
      "Epoch 45/75\n",
      "51422/51422 [==============================] - 453s 9ms/step - loss: 3.3505 - acc: 0.2589\n",
      "Epoch 46/75\n",
      "51422/51422 [==============================] - 448s 9ms/step - loss: 3.3113 - acc: 0.2662\n",
      "Epoch 47/75\n",
      "51422/51422 [==============================] - 448s 9ms/step - loss: 3.3232 - acc: 0.2664\n",
      "Epoch 48/75\n",
      "51422/51422 [==============================] - 450s 9ms/step - loss: 3.2610 - acc: 0.2730\n",
      "Epoch 49/75\n",
      "51422/51422 [==============================] - 450s 9ms/step - loss: 3.2505 - acc: 0.2748\n",
      "Epoch 50/75\n",
      "51422/51422 [==============================] - 450s 9ms/step - loss: 3.2856 - acc: 0.2771\n",
      "Epoch 51/75\n",
      "51422/51422 [==============================] - 450s 9ms/step - loss: 3.1842 - acc: 0.2860\n",
      "Epoch 52/75\n",
      "51422/51422 [==============================] - 449s 9ms/step - loss: 3.1172 - acc: 0.2948\n",
      "Epoch 53/75\n",
      "51422/51422 [==============================] - 455s 9ms/step - loss: 3.1662 - acc: 0.2918\n",
      "Epoch 54/75\n",
      "51422/51422 [==============================] - 454s 9ms/step - loss: 3.4129 - acc: 0.2656\n",
      "Epoch 55/75\n",
      "51422/51422 [==============================] - 449s 9ms/step - loss: 3.3144 - acc: 0.2733\n",
      "Epoch 56/75\n",
      "51422/51422 [==============================] - 551s 11ms/step - loss: 3.2530 - acc: 0.2807\n",
      "Epoch 57/75\n",
      "51422/51422 [==============================] - 539s 10ms/step - loss: 3.1926 - acc: 0.2868\n",
      "Epoch 58/75\n",
      "51422/51422 [==============================] - 532s 10ms/step - loss: 3.1441 - acc: 0.2928\n",
      "Epoch 59/75\n",
      "51422/51422 [==============================] - 529s 10ms/step - loss: 3.0970 - acc: 0.2979\n",
      "Epoch 60/75\n",
      "51422/51422 [==============================] - 541s 11ms/step - loss: 3.0582 - acc: 0.3036\n",
      "Epoch 61/75\n",
      "51422/51422 [==============================] - 524s 10ms/step - loss: 3.0121 - acc: 0.3111\n",
      "Epoch 62/75\n",
      "51422/51422 [==============================] - 530s 10ms/step - loss: 2.9672 - acc: 0.3175\n",
      "Epoch 63/75\n",
      "51422/51422 [==============================] - 532s 10ms/step - loss: 2.9369 - acc: 0.3231\n",
      "Epoch 64/75\n",
      "51422/51422 [==============================] - 544s 11ms/step - loss: 2.8845 - acc: 0.3300\n",
      "Epoch 65/75\n",
      "51422/51422 [==============================] - 579s 11ms/step - loss: 2.8595 - acc: 0.3357\n",
      "Epoch 66/75\n",
      "51422/51422 [==============================] - 525s 10ms/step - loss: 2.8161 - acc: 0.3400\n",
      "Epoch 67/75\n",
      "51422/51422 [==============================] - 458s 9ms/step - loss: 2.7810 - acc: 0.3441\n",
      "Epoch 68/75\n",
      "51422/51422 [==============================] - 516s 10ms/step - loss: 2.7346 - acc: 0.3547\n",
      "Epoch 69/75\n",
      "51422/51422 [==============================] - 522s 10ms/step - loss: 2.7065 - acc: 0.3570\n",
      "Epoch 70/75\n",
      "51422/51422 [==============================] - 458s 9ms/step - loss: 2.6710 - acc: 0.3642\n",
      "Epoch 71/75\n",
      "51422/51422 [==============================] - 449s 9ms/step - loss: 2.6264 - acc: 0.3716\n",
      "Epoch 72/75\n",
      "51422/51422 [==============================] - 450s 9ms/step - loss: 2.6027 - acc: 0.3766\n",
      "Epoch 73/75\n",
      "51422/51422 [==============================] - 461s 9ms/step - loss: 2.5761 - acc: 0.3784\n",
      "Epoch 74/75\n",
      "51422/51422 [==============================] - 454s 9ms/step - loss: 2.5370 - acc: 0.3874\n",
      "Epoch 75/75\n",
      "51422/51422 [==============================] - 450s 9ms/step - loss: 2.5038 - acc: 0.3938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1131338d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(Input, Output, batch_size=250, epochs=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the model to file\n",
    "model.save('junglebook_trained.h5')\n",
    "# save the tokenizer\n",
    "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_document(name):\n",
    "    file = open(name, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    " \n",
    "# load cleaned text sequences\n",
    "input_filename = 'junglebook_sequences.txt'\n",
    "doc = load_document(input_filename)\n",
    "lines = doc.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_length = len(lines[0].split()) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "from keras.models import load_model\n",
    "model = load_model('junglebook_trained.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to me not long ago with some rude talk that i was a naked cub and not fit to dig pignuts but i caught tabaqui by the tail and swung him twice against a palmtree to teach him better was foolishness for though tabaqui is a mischiefmaker he would have told\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select a seed text\n",
    "from random import randint\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "print(seed_text + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded = tokenizer.texts_to_sequences([seed_text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    " \n",
    "# load doc into memory\n",
    "def load_document(name):\n",
    "    file = open(name, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    " \n",
    "# generate a sequence from a language model\n",
    "def generate_sequence(model, tokenizer, sequence_length, seed_text, n_words):\n",
    "\tresult = list()\n",
    "\tinput_text = seed_text\n",
    "\t# generate a fixed number of words\n",
    "\tfor _ in range(n_words):\n",
    "\t\t# encode the text as integer\n",
    "\t\tencoded = tokenizer.texts_to_sequences([input_text])[0]\n",
    "\t\t# truncate sequences to a fixed length\n",
    "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "\t\t# predict probabilities for each word\n",
    "\t\tprediction = model.predict_classes(encoded, verbose=0)\n",
    "\t\t# map predicted word index to word\n",
    "\t\tout_word = ''\n",
    "\t\tfor word, index in tokenizer.word_index.items():\n",
    "\t\t\tif index == prediction:\n",
    "\t\t\t\tout_word = word\n",
    "\t\t\t\tbreak\n",
    "\t\t# append to input\n",
    "\t\tinput_text += ' ' + out_word\n",
    "\t\tresult.append(out_word)\n",
    "\treturn ' '.join(result)\n",
    " \n",
    "# load cleaned text sequences\n",
    "input_filename = 'junglebook_sequences.txt'\n",
    "doc = load_document(input_filename)\n",
    "lines = doc.split('\\n')\n",
    "seq_length = len(lines[0].split()) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baskets of dried grass and put grasshoppers in them or catch two praying mantises and make them fight or string a necklace of red and black jungle nuts or watch a lizard basking on a rock or a snake hunting a frog near the wallows then they sing long long songs\n",
      "\n",
      "with odd native quavers at the end of the review and the hyaena whom he had seen the truth they feel twitched to the noises round him for a picture of the end of the ravine and snuffing bitten and best of the bulls at the dawn is a native\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = load_model('junglebook_trained.h5')\n",
    " \n",
    "# load the tokenizer\n",
    "tokenizer = load(open('tokenizer.pkl', 'rb'))\n",
    " \n",
    "# select a seed text\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "print(seed_text + '\\n')\n",
    " \n",
    "# generate new text\n",
    "generated = generate_sequence(model, tokenizer, sequence_length, seed_text, 50)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "little toomai there was a splash and a trample and the rush of running water and kala nag strode through the bed of a river feeling his way at each step above the noise of the water as it swirled round the legs little toomai could hear more splashing and some\n",
      "\n",
      "trumpeting both upstream and down grass and knocked him up to the jealous moon he could see bruised of dust for the potter was rann caught him up to the plowed din of the melbourne lines where the two wolves would be forced to make themselves rifles and the sparks\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = load_model('junglebook_trained.h5')\n",
    " \n",
    "# load the tokenizer\n",
    "tokenizer = load(open('tokenizer.pkl', 'rb'))\n",
    " \n",
    "# select a seed text\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "print(seed_text + '\\n')\n",
    " \n",
    "# generate new text\n",
    "generated = generate_sequence(model, tokenizer, sequence_length, seed_text, 50)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is in their legs and he remembered the good firm beaches of novastoshnah seven thousand miles away the games his companions played the smell of the seaweed the seal roar and the fighting that very minute he turned north swimming steadily and as he went on he met scores of his\n",
      "\n",
      "mates and bound like the deck of the fighters and harness under his breath and he could not be able to stop a ship and ducked to nag wound up with scores of marble tracery showing all the regiments went twisting his head and shoulders and creepers very seldom shows\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = load_model('junglebook_trained.h5')\n",
    " \n",
    "# load the tokenizer\n",
    "tokenizer = load(open('tokenizer.pkl', 'rb'))\n",
    " \n",
    "# select a seed text\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "print(seed_text + '\\n')\n",
    " \n",
    "# generate new text\n",
    "generated = generate_sequence(model, tokenizer, sequence_length, seed_text, 50)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
